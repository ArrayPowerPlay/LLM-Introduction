{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57dcbbb5",
   "metadata": {},
   "source": [
    "# Fine-tuning a masked language model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870e828d",
   "metadata": {},
   "source": [
    "For many NLP applications involving Transformer models, you can simply take a pretrained model from the Hugging Face Hub and fine-tune it directly on your data for the task at hand. Provided that the corpus used for pretraining is not too different from the corpus used for fine-tuning, transfer learning will usually produce good results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e53352",
   "metadata": {},
   "source": [
    "However, there are a few cases where you’ll want to first fine-tune the language models on your data, before training a task-specific head. For example, if your dataset contains legal contracts or scientific articles, a vanilla Transformer model like BERT will typically treat the domain-specific words in your corpus as rare tokens, and the resulting performance may be less than satisfactory. By fine-tuning the language model on in-domain data you can boost the performance of many downstream tasks, which means you usually only have to do this step once!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff500922",
   "metadata": {},
   "source": [
    "This process of fine-tuning a pretrained language model on in-domain data is usually called **domain adaptation**. It was popularized in 2018 by ULMFiT, which was one of the first neural architectures (based on LSTMs) to make transfer learning really work for NLP. An example of domain adaptation with ULMFiT is shown in the image below; in this section we’ll do something similar, but with a Transformer instead of an LSTM!\n",
    "\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5ebc55cb",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62835b4d",
   "metadata": {},
   "source": [
    "## 1. Picking a pretrained model for masked language modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da4f91",
   "metadata": {},
   "source": [
    "Although the BERT and RoBERTa family of models are the most downloaded, we’ll use a model called DistilBERT that can be trained much faster with little to no loss in downstream performance. This model was trained using a special technique called knowledge distillation, where a large “teacher model” like BERT is used to guide the training of a “student model” that has far fewer parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10eec566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44a81674c1d42808da48909e25421ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704cee1",
   "metadata": {},
   "source": [
    "We can see how many parameters this model has by calling the `num_parameters()` method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "508abafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.98553 million parameters\n"
     ]
    }
   ],
   "source": [
    "distilbert_num_params = model.num_parameters() / 1_000_000\n",
    "print(f'{distilbert_num_params} million parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6020edc",
   "metadata": {},
   "source": [
    "With around 67 million parameters, DistilBERT is approximately two times smaller than the BERT base model, which roughly translates into a two-fold speedup in training — nice! Let’s now see what kinds of tokens this model predicts are the most likely completions of a small sample of text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ed671d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is a great [MASK].\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbaf998",
   "metadata": {},
   "source": [
    "For pretrained models, the predictions depend on the corpus the model was trained on, since it learns to pick up the statistical patterns present in the data. Like BERT, DistilBERT was pretrained on the English Wikipedia and BookCorpus datasets, so we expect the predictions for `[MASK]` to reflect these domains. To predict the mask we need DistilBERT’s tokenizer to produce the inputs for the model, so let’s download that from the Hub as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e12d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e13b67",
   "metadata": {},
   "source": [
    "With a tokenizer and a model, we can now pass our text example to the model, extract the logits, and print out the top 5 candidates:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daae4018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 30522])\n",
      "This is a great deal.\n",
      "This is a great success.\n",
      "This is a great adventure.\n",
      "This is a great idea.\n",
      "This is a great feat.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "logits = model(**inputs).logits\n",
    "print(logits.shape)\n",
    "# Find the location of [MASK]\n",
    "mask_token_idx = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "mask_token_logits = logits[0, mask_token_idx, :]\n",
    "# topk function return values, indices -> shape of indices is (1, 5)\n",
    "# 1 mask position, 5 highest probability logits\n",
    "top5_tokens = torch.topk(mask_token_logits, 5, dim=-1).indices[0].tolist()\n",
    "\n",
    "for token in top5_tokens:\n",
    "    print(f\"{text.replace(tokenizer.mask_token, tokenizer.decode([token]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfbe9c5",
   "metadata": {},
   "source": [
    "## 2. The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c0775",
   "metadata": {},
   "source": [
    "To showcase domain adaptation, we’ll use the famous Large Movie Review Dataset (or IMDb for short), which is a corpus of movie reviews that is often used to benchmark sentiment analysis models. By fine-tuning DistilBERT on this corpus, we expect the language model will adapt its vocabulary from the factual data of Wikipedia that it was pretrained on to the more subjective elements of movie reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78f04f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imdb_dataset = load_dataset('imdb')\n",
    "imdb_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714cbc3e",
   "metadata": {},
   "source": [
    "We can see that the `train` and `test` splits each consist of 25,000 reviews, while there is an unlabeled split called `unsupervised` that contains 50,000 reviews. Let’s take a look at a few samples to get an idea of what kind of text we’re dealing with. As we’ve done in previous chapters of the course, we’ll chain the `Dataset.shuffle()` and` Dataset.select()` functions to create a random sample:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9931c368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier's plot are far more complicated... Fortier looks more like Prime Suspect, if we have to spot similarities... The main character is weak and weirdo, but have \"clairvoyance\". People like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it's the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all...\n",
      "1\n",
      "This movie is a great. The plot is very true to the book which is a classic written by Mark Twain. The movie starts of with a scene where Hank sings a song with a bunch of kids called \"when you stub your toe on the moon\" It reminds me of Sinatra's song High Hopes, it is fun and inspirational. The Music is great throughout and my favorite song is sung by the King, Hank (bing Crosby) and Sir \"Saggy\" Sagamore. OVerall a great family movie or even a great Date movie. This is a movie you can watch over and over again. The princess played by Rhonda Fleming is gorgeous. I love this movie!! If you liked Danny Kaye in the Court Jester then you will definitely like this movie.\n",
      "1\n",
      "George P. Cosmatos' \"Rambo: First Blood Part II\" is pure wish-fulfillment. The United States clearly didn't win the war in Vietnam. They caused damage to this country beyond the imaginable and this movie continues the fairy story of the oh-so innocent soldiers. The only bad guys were the leaders of the nation, who made this war happen. The character of Rambo is perfect to notice this. He is extremely patriotic, bemoans that US-Americans didn't appreciate and celebrate the achievements of the single soldier, but has nothing but distrust for leading officers and politicians. Like every film that defends the war (e.g. \"We Were Soldiers\") also this one avoids the need to give a comprehensible reason for the engagement in South Asia. And for that matter also the reason for every single US-American soldier that was there. Instead, Rambo gets to take revenge for the wounds of a whole nation. It would have been better to work on how to deal with the memories, rather than suppressing them. \"Do we get to win this time?\" Yes, you do.\n",
      "0\n",
      "In the process of trying to establish the audiences' empathy with Jake Roedel (Tobey Maguire) the filmmakers slander the North and the Jayhawkers. Missouri never withdrew from the Union and the Union Army was not an invading force. The Southerners fought for State's Rights: the right to own slaves, elect crooked legislatures and judges, and employ a political spoils system. There's nothing noble in that. The Missourians could have easily traveled east and joined the Confederate Army.<br /><br />It seems to me that the story has nothing to do with ambiguity. When Jake leaves the Bushwhackers, it's not because he saw error in his way, he certainly doesn't give himself over to the virtue of the cause of abolition.\n",
      "1\n",
      "Yeh, I know -- you're quivering with excitement. Well, *The Secret Lives of Dentists* will not upset your expectations: it's solidly made but essentially unimaginative, truthful but dull. It concerns the story of a married couple who happen to be dentists and who share the same practice (already a recipe for trouble: if it wasn't for our separate work-lives, we'd all ditch our spouses out of sheer irritation). Campbell Scott, whose mustache and demeanor don't recall Everyman so much as Ned Flanders from *The Simpsons*, is the mild-mannered, uber-Dad husband, and Hope Davis is the bored-stiff housewife who channels her frustrations into amateur opera. One night, as Dad & the daughters attend one of Davis' performances, he discovers that his wife is channeling her frustrations into more than just singing: he witnesses his wife kissing and flirting with the director of opera. (One nice touch: we never see the opera-director's face.) Dreading the prospect of instituting the proceedings for separation, divorce, and custody hearings -- profitable only to the lawyers -- Scott chooses to pretend ignorance of his wife's indiscretions.<br /><br />Already, the literate among you are starting to yawn: ho-hum, another story about the Pathetic, Sniveling Little Cuckold. But Rudolph, who took the story from a Jane Smiley novella, hopes that the wellworn-ness of the material will be compensated for by a series of flashy, postmodern touches. For instance, one of Scott's belligerent patients (Denis Leary, kept relatively -- and blessedly -- in check) will later become a sort of construction of the dentist's imagination, emerging as a Devil-on-the-shoulder advocate for the old-fashioned masculine virtues (\"Dump the b---h!\", etc.). When not egged-on by his imaginary new buddy, Scott is otherwise tormented by fantasies that include his wife engaged in a three-way with two of the male dental-assistants who work in their practice. It's not going too far to say that this movie is *Eyes Wide Shut* for Real People (or Grown-Ups, at least). Along those lines, Campbell Scott and Hope Davis are certainly recognizable human beings as compared to the glamourpuss pair of Cruise and Kidman. Further, the script for *Secret Lives* is clearly more relevant than Kubrick's. As proof, I offer the depiction of the dentists' children, particularly the youngest one who is about 3 or 4 years old, and whose main utterance is \"Dad! Dad! Dad! Dad! Dad! DAD!!!\" This is Family Life, all right, with all its charms.<br /><br />The movie would make an interesting double-bill with *Kramer vs. Kramer*, as well. One can easily trace the Feminization of the American Male from 1979 to 2003. In this movie, Dad is the housewife as in *Kramer*, but he is in no way flustered by the domestic role, unlike Dustin Hoffman, who was too manly to make toast. Here, Scott gets all the plumb chores, such as wiping up the children's vomit, cooking, cleaning, taking the kids to whatever inane after-school activity is on the docket. And all without complaint. (And without directorial commentary. It's just taken for granted.)<br /><br />The film has virtues, mostly having to do with verisimilitude. However, it's dragged down from greatness by its insistence on trendy distractions, which culminate in a long scene where a horrible five-day stomach flu makes the rounds in the household. We must endure pointless fantasy sequences, initiated by the imaginary ringleader Leary. Whose existence, by the way, is finally reminiscent of the Brad Pitt character in *Fight Club*. And this finally drives home the film's other big flaw: lack of originality. In this review, I realize it's been far too easy to reference many other films. Granted, this film is an improvement on most of them, but still. *The Secret Lives of Dentists* is worth seeing, but don't get too excited about it. (Not that you were all that excited, anyway. I guess.)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "sample = imdb_dataset[\"train\"].shuffle(seed=42).select(range(5))\n",
    "\n",
    "for row in sample:\n",
    "    print(row[\"text\"])\n",
    "    print(row[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c76852",
   "metadata": {},
   "source": [
    "Although we won’t need the labels for language modeling, we can already see that a 0 denotes a negative review, while a 1 corresponds to a positive one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "822e1ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['This is just a precious little diamond. The play, the script are excellent. I cant compare this movie with anything else, maybe except the movie \"Leon\" wonderfully played by Jean Reno and Natalie Portman. But... What can I say about this one? This is the best movie Anne Parillaud has ever played in (See please \"Frankie Starlight\", she\\'s speaking English there) to see what I mean. The story of young punk girl Nikita, taken into the depraved world of the secret government forces has been exceptionally over used by Americans. Never mind the \"Point of no return\" and especially the \"La femme Nikita\" TV series. They cannot compare the original believe me! Trash these videos. Buy this one, do not rent it, BUY it. BTW beware of the subtitles of the LA company which \"translate\" the US release. What a disgrace! If you cant understand French, get a dubbed version. But you\\'ll regret later :)',\n",
       "  'When I say this is my favourite film of all time, that comment is not to be taken lightly. I probably watch far too many films than is healthy for me, and have loved quite a few of them. I first saw \"La Femme Nikita\" nearly ten years ago, and it still manages to be my absolute favourite. Why?<br /><br />This is more than an incredibly stylish and sexy thriller. Luc Besson\\'s great flair for impeccable direction, fashion, and appropriate usage of music makes this a very watchable film. But it is Anne Parillaud\\'s perfect rendering of a complex character who transforms from a heartless killer into a compassionate, vibrant young woman that makes this film beautiful. I can\\'t keep my eyes off of her when she is on screen.<br /><br />I have seen several of Luc Besson\\'s films including \"Subway\", \"The Professional\", and the irritating \"Fifth Element\", and \"Nikita\" is without a doubt, far superior to any of these. Although this film has tragic elements, it is ultimately extremely hopeful. It is the story of a person who is cruel and merciless, who ultimately comes to realize her own humanity and her own personal power. That, to me is extremely inspiring. If there is hope for Nikita, there is hope for all of us.',\n",
       "  'I saw this movie because I am a huge fan of the TV series of the same name starring Roy Dupuis and Pet Wilson. The movie was really good and I saw how the TV show is based on the movie. A few episodes of the TV series came directly from the movie and their similarity was amazing. To keep things short, any fan of the movie has to watch the series and any fan of the series must see the original Nikita.'],\n",
       " 'label': [-1, -1, -1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_dataset[\"unsupervised\"][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ef4486",
   "metadata": {},
   "source": [
    "## 3. Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc4a8e4",
   "metadata": {},
   "source": [
    "For both auto-regressive and masked language modeling, a common preprocessing step is to concatenate all the examples and then split the whole corpus into chunks of equal size. This is quite different from our usual approach, where we simply tokenize individual examples. Why concatenate everything together? The reason is that individual examples might get truncated if they’re too long, and that would result in losing information that might be useful for the language modeling task!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2993cf6",
   "metadata": {},
   "source": [
    "So to get started, we’ll first tokenize our corpus as usual, but without setting the `truncation=True` option in our tokenizer. We’ll also grab the word IDs, as we will need them later on to do whole word masking. We’ll wrap this in a simple function, and while we’re at it we’ll remove the text and label columns since we don’t need them any longer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833e0248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(example):\n",
    "    # DataCollatorForWholeWordMask cần offset_mapping hợp lệ\n",
    "    result = tokenizer(example[\"text\"], return_offsets_mapping=True)\n",
    "    result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44e3acdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8db9b1e73a3466db7f11a5ce1b22807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'word_ids'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'word_ids'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'word_ids'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = imdb_dataset.map(\n",
    "    tokenize_func, \n",
    "    batched=True, \n",
    "    remove_columns=imdb_dataset[\"train\"].column_names\n",
    ")\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3cfcd8",
   "metadata": {},
   "source": [
    "Since DistilBERT is a BERT-like model, we can see that the encoded texts consist of the `input_ids` and `attention_mask` that we’ve seen in other chapters, as well as the `word_ids` we added.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5f2f07",
   "metadata": {},
   "source": [
    "Now that we’ve tokenized our movie reviews, the next step is to group them all together and split the result into chunks. But how big should these chunks be? This will ultimately be determined by the amount of GPU memory that you have available, but a good starting point is to see what the model’s maximum context size is. This can be inferred by inspecting the `model_max_length` attribute of the tokenizer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cd6b489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc84fd7",
   "metadata": {},
   "source": [
    "This value is derived from the `tokenizer_config.json` file associated with a checkpoint; in this case we can see that the context size is 512 tokens, just like with BERT.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746915e4",
   "metadata": {},
   "source": [
    "So, in order to run our experiments on GPUs like those found on Google Colab, we’ll pick something a bit smaller that can fit in memory:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "515f4fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26fd4a1",
   "metadata": {},
   "source": [
    "Note that using a small chunk size can be detrimental in real-world scenarios, so you should use a size that corresponds to the use case you will apply your model to.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc3c722",
   "metadata": {},
   "source": [
    "Now comes the fun part. To show how the concatenation works, let’s take a few reviews from our tokenized training set and print out the number of tokens per review:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "912a81f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Review 0 length: 363'\n",
      "'>>> Review 1 length: 304'\n",
      "'>>> Review 2 length: 133'\n"
     ]
    }
   ],
   "source": [
    "# Slicing produces a list of lists for each feature\n",
    "tokenized_samples = tokenized_dataset[\"train\"][:3]\n",
    "\n",
    "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
    "    print(f\"'>>> Review {idx} length: {len(sample)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eebfab",
   "metadata": {},
   "source": [
    "We can then concatenate all these examples with a simple dictionary comprehension, as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90c353e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": [
    "concatenated_example = {\n",
    "    k: sum(tokenized_samples[k], []) \n",
    "    for k in tokenized_samples.keys()\n",
    "}\n",
    "\n",
    "total_length = len(concatenated_example[\"input_ids\"])\n",
    "print(total_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c88729a",
   "metadata": {},
   "source": [
    "Great, the total length checks out — so now let’s split the concatenated reviews into chunks of the size given by `chunk_size`. To do so, we iterate over the features in `concatenated_examples` and use a list comprehension to create slices of each feature. The result is a dictionary of chunks for each feature:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57dfdf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "256\n",
      "256\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "chunks = {\n",
    "    k: [t[i: i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "    for k, t in concatenated_example.items()\n",
    "}\n",
    "for chunk in chunks[\"input_ids\"]:\n",
    "    print(len(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e649532",
   "metadata": {},
   "source": [
    "As you can see in this example, the last chunk will generally be smaller than the maximum chunk size. There are two main strategies for dealing with this:\n",
    "\n",
    "1. Drop the last chunk if it’s smaller than `chunk_size`.\n",
    "\n",
    "2. Pad the last chunk until its length equals `chunk_size`.\n",
    "\n",
    "We’ll take the first approach here, so let’s wrap all of the above logic in a single function that we can apply to our tokenized datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be637485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concat all texts\n",
    "    concatenated_example = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_example[list(examples.keys())[0]])\n",
    "    # Drop the last chunk\n",
    "    total_length = total_length // chunk_size * chunk_size\n",
    "    result = {\n",
    "        k: [t[i: i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_example.items()\n",
    "    }\n",
    "    # Add 'labels' column\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f5dfc4",
   "metadata": {},
   "source": [
    "Note that in the last step of `group_texts()` we create a new labels column which is a copy of the `input_ids` one. As we’ll see shortly, that’s because in masked language modeling the objective is to predict randomly masked tokens in the input batch, and by creating a labels column we provide the ground truth for our language model to learn from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4456ed22",
   "metadata": {},
   "source": [
    "Let’s now apply `group_texts()` to our tokenized datasets using our trusty `Dataset.map()` function:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afecd740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e20c7eb6ea44b309de4db6fa1427e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae538226b4547d486348f9537f9d4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'word_ids', 'labels'],\n",
       "        num_rows: 30639\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'word_ids', 'labels'],\n",
       "        num_rows: 29946\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'word_ids', 'labels'],\n",
       "        num_rows: 61465\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset = tokenized_dataset.map(group_texts, batched=True)\n",
    "lm_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f4bfed",
   "metadata": {},
   "source": [
    "You can see that grouping and then chunking the texts has produced many more examples than our original 25,000 for the `train` and `test` splits. That’s because we now have examples involving contiguous tokens that span across multiple examples from the original corpus. You can see this explicitly by looking for the special `[SEP]` and `[CLS]` tokens in one of the chunks:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b479fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'[CLS] i rented i am curious - yellow from my video store because of all the controversy that surrounded it when it was first released in 1967. i also heard that at first it was seized by u. s. customs if it ever tried to enter this country, therefore being a fan of films considered \" controversial \" i really had to see this for myself. < br / > < br / > the plot is centered around a young swedish drama student named lena who wants to learn everything she can about life. in particular she wants to focus her attentions to making some sort of documentary on what the average swede thought about certain political issues such as the vietnam war and race issues in the united states. in between asking politicians and ordinary denizens of stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men. < br / > < br / > what kills me about i am curious - yellow is that 40 years ago, this was considered pornographic. really, the sex and nudity scenes are few and far between, even then it \\' s not shot like some cheaply made porno. while my countrymen mind find it shocking, in reality sex and nudity are a major staple in swedish cinema. even ingmar bergman,'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_dataset[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0df0ff",
   "metadata": {},
   "source": [
    "Let’s also check out what the labels look like for masked language modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "257fd3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'[CLS] i rented i am curious - yellow from my video store because of all the controversy that surrounded it when it was first released in 1967. i also heard that at first it was seized by u. s. customs if it ever tried to enter this country, therefore being a fan of films considered \" controversial \" i really had to see this for myself. < br / > < br / > the plot is centered around a young swedish drama student named lena who wants to learn everything she can about life. in particular she wants to focus her attentions to making some sort of documentary on what the average swede thought about certain political issues such as the vietnam war and race issues in the united states. in between asking politicians and ordinary denizens of stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men. < br / > < br / > what kills me about i am curious - yellow is that 40 years ago, this was considered pornographic. really, the sex and nudity scenes are few and far between, even then it \\' s not shot like some cheaply made porno. while my countrymen mind find it shocking, in reality sex and nudity are a major staple in swedish cinema. even ingmar bergman,'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_dataset[\"train\"][0][\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d3285",
   "metadata": {},
   "source": [
    "As expected from our `group_texts()` function above, this looks identical to the decoded `input_ids` — but then how can our model possibly learn anything? We’re missing a key step: inserting `[MASK]` tokens at random positions in the inputs! Let’s see how we can do this on the fly during fine-tuning using a special data collator.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84fcb78",
   "metadata": {},
   "source": [
    "## 4. Fine-tuning DistilBERT with the Trainer API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa29920",
   "metadata": {},
   "source": [
    "Fine-tuning a masked language model is almost identical to fine-tuning a sequence classification model. The only difference is that we need a special data collator that can randomly mask some of the tokens in each batch of texts. Fortunately, 🤗 Transformers comes prepared with a dedicated `DataCollatorForLanguageModeling` for just this task. We just have to pass it the tokenizer and an `mlm_probability` argument that specifies what fraction of the tokens to mask. We’ll pick 15%, which is the amount used for BERT and a common choice in the literature:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9d7b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69f5d10",
   "metadata": {},
   "source": [
    "To see how the random masking works, let’s feed a few examples to the data collator. Since it expects a list of `dicts`, where each `dict` represents a single chunk of contiguous text, we first iterate over the dataset before feeding the batch to the collator. We remove the `\"word_ids\"` key for this data collator as it does not expect it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41e9d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'i', '[MASK]', 'i', 'am', 'curious', '-', 'yellow', '[MASK]', 'my', 'video', 'store', 'because', 'of', 'all', 'the', 'controversy', 'that', 'surrounded', 'it', 'when', 'it', 'was', 'first', 'released', 'in', '1967', '.', 'i', 'also', 'heard', '[MASK]', '[MASK]', 'first', 'it', 'was', 'seized', 'by', 'u', '.', 's', '.', 'customs', 'if', 'it', '[MASK]', 'tried', 'to', 'enter', '[MASK]', 'country', ',', 'therefore', 'being', 'a', 'fan', '[MASK]', 'films', 'considered', '[MASK]', 'controversial', '\"', 'i', 'really', 'had', '[MASK]', 'see', '[MASK]', 'for', 'myself', '.', '<', '[MASK]', '/', '>', '<', 'br', '/', '>', 'the', 'plot', 'is', 'centered', 'around', 'a', 'norms', '[MASK]', 'clyde', 'student', '[MASK]', 'lena', 'who', 'wants', 'to', 'learn', '[MASK]', 'she', '[MASK]', 'about', 'life', '.', 'in', 'particular', 'she', 'wants', 'to', '[MASK]', 'her', 'attention', '##s', 'to', 'making', 'some', 'sort', 'of', 'documentary', 'on', 'what', 'the', '[MASK]', 'sw', '##ede', '[MASK]', 'about', '[MASK]', 'political', '[MASK]', 'such', '[MASK]', 'the', 'vietnam', 'war', 'and', 'race', 'issues', 'in', 'the', 'united', '[MASK]', '.', 'in', 'between', 'asking', 'politicians', 'and', 'ordinary', 'den', '##ize', '##ns', 'pity', 'stockholm', 'about', 'their', 'opinions', 'on', 'politics', ',', '[MASK]', 'has', 'sex', 'with', 'her', 'drama', 'teacher', ',', '[MASK]', '[MASK]', '[MASK]', 'married', 'men', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'what', 'kills', 'me', 'about', 'i', 'am', 'curious', '-', '[MASK]', 'is', 'that', '40', '[MASK]', 'ago', ',', 'this', 'was', 'considered', 'pornographic', '.', 'really', ',', 'the', 'sex', 'and', 'nu', '##dity', 'scenes', '[MASK]', 'few', 'and', 'far', 'between', '[MASK]', 'even', 'then', '[MASK]', \"'\", 's', '##lates', 'shot', 'like', 'some', 'cheap', '##ly', 'made', 'porn', '##o', '.', 'while', 'my', 'country', '##men', 'mind', '[MASK]', '[MASK]', 'shocking', ',', 'in', 'reality', 'sex', '[MASK]', 'nu', '##dity', 'are', 'a', 'major', 'staple', 'in', 'swedish', 'cinema', '.', 'even', 'ing', 'serialized', 'bergman', ',']\n",
      "\n",
      "['[MASK]', 'their', 'answer', 'to', 'good', 'old', 'boy', '[MASK]', 'ford', ',', '[MASK]', 'sex', 'scenes', 'in', 'his', 'films', '.', '<', 'br', '/', '>', '<', 'br', 'ru', '[MASK]', 'i', 'do', 'com', '##men', '##d', 'shuffled', 'filmmakers', 'for', 'the', '[MASK]', 'that', 'any', 'sex', 'shown', 'in', 'the', 'film', 'is', 'shown', 'for', 'artistic', 'purposes', 'rather', 'than', 'just', 'to', 'shock', 'people', 'and', 'make', 'money', 'to', 'be', 'repeatedly', 'in', 'pornographic', 'theaters', 'in', '[MASK]', '.', 'i', 'am', 'curious', '-', 'yellow', 'is', 'a', 'good', 'film', '[MASK]', 'anyone', 'wanting', '[MASK]', 'study', 'the', '[MASK]', '[MASK]', 'potatoes', '[MASK]', 'no', '[MASK]', 'intended', ')', 'of', '[MASK]', 'cinema', '.', 'but', 'really', ',', 'this', 'film', 'doesn', '[MASK]', 't', 'have', 'much', 'of', '[MASK]', 'plot', '.', '[SEP]', '[CLS]', '[MASK]', 'i', 'am', 'curious', ':', 'yellow', '\"', 'is', '[MASK]', 'ri', '##sible', 'and', 'pre', '##ten', '##tious', '##poo', 'pile', '.', 'it', 'doesn', \"'\", 't', 'matter', 'what', 'one', \"'\", '[MASK]', 'political', 'views', '[MASK]', 'because', 'this', '[MASK]', 'can', 'hardly', '[MASK]', 'taken', 'seriously', 'on', 'any', 'level', '.', 'as', 'for', 'the', 'claim', 'that', 'frontal', 'male', 'nu', '##dity', 'is', 'an', 'automatic', 'nc', '[MASK]', '17', ',', 'that', '[MASK]', \"'\", 't', 'true', '.', 'i', \"'\", '[MASK]', 'seen', 'r', '-', 'rated', 'films', 'with', 'male', 'nu', '##dity', '.', 'granted', ',', 'they', 'only', 'offer', 'some', 'fleeting', 'views', ',', 'but', 'where', 'are', 'the', 'r', '-', '[MASK]', 'films', 'with', 'gaping', 'vu', '[MASK]', '##s', 'and', 'flap', '##ping', 'lab', '[MASK]', '?', 'nowhere', ',', 'because', 'they', 'don', \"'\", 't', 'exist', 'pan', 'the', 'same', 'goes', '[MASK]', 'those', 'crap', '##py', 'cable', 'shows', ':', 'sc', '##hl', '##ong', '##s', 'swinging', 'in', '[MASK]', 'breeze', '[MASK]', 'not', 'a', 'clit', '##oris', 'in', 'sight', '.', 'and', 'those', 'pre', '##ten', '##tious', 'indie', 'movies', 'like']\n",
      "\n",
      "['the', 'brown', '[MASK]', '[MASK]', 'in', 'which', 'we', \"'\", '[MASK]', 'treated', 'to', 'the', '[MASK]', '[MASK]', 'vincent', 'gallo', \"'\", 's', 'throbbing', 'johnson', ',', 'but', '[MASK]', '[MASK]', 'trace', 'of', 'pink', 'visible', 'on', 'chloe', 'se', '##vi', '##gny', '[MASK]', 'before', 'crying', '(', '[MASK]', 'implying', ')', '\"', 'double', '-', 'standard', '\"', 'in', 'matters', 'of', 'nu', '##dity', '[MASK]', 'the', '[MASK]', 'ob', '##tus', '##e', 'should', 'take', '[MASK]', 'account', '[MASK]', '[MASK]', '##vo', '##ida', 'assassins', 'obvious', 'anatomical', 'difference', 'between', 'men', 'and', 'women', ':', 'there', 'are', 'no', 'gen', '##ital', '[MASK]', 'on', 'display', 'when', 'actresses', 'appears', 'nude', '[MASK]', 'and', 'the', 'same', '[MASK]', 'be', 'said', 'for', 'a', 'man', '.', 'in', 'fact', ',', 'you', 'generally', 'won', \"'\", 't', '[MASK]', 'female', 'gen', '[MASK]', '##s', 'in', 'an', 'american', 'film', 'in', 'anything', '[MASK]', 'of', 'porn', 'or', '[MASK]', 'erotic', '##a', '.', '[MASK]', '[MASK]', '[MASK]', '-', 'standard', 'is', 'less', 'a', 'double', 'standard', 'than', 'an', 'admitted', '##ly', '[MASK]', '##pressing', 'ability', 'to', 'come', 'to', 'terms', '[MASK]', '[MASK]', 'the', 'insides', 'of', 'women', \"'\", 's', 'bodies', '.', '[SEP]', '[CLS]', 'if', 'only', 'to', 'avoid', 'making', 'this', '[MASK]', 'of', 'film', 'in', 'the', 'future', '.', 'this', 'film', 'is', 'interesting', 'as', 'an', 'experiment', 'but', 'tells', 'no', 'co', '[MASK]', 'story', '.', '<', '[MASK]', '/', '>', '<', 'br', '/', '[MASK]', 'one', 'might', '[MASK]', 'vi', '##rt', '##uous', 'for', 'sitting', 'thru', 'it', 'because', 'it', 'touches', 'on', 'so', 'many', 'important', 'issues', 'but', 'it', '[MASK]', 'so', 'without', 'any', 'disc', '##ern', '##able', 'motive', '.', 'the', 'viewer', 'comes', 'away', 'with', '[MASK]', 'new', '[MASK]', '(', 'unless', 'one', 'comes', 'up', 'with', '[MASK]', 'while', 'one', '[MASK]', 's', 'mind', 'wander', '[MASK]', ',', 'as', 'it', 'will', 'invariably', '[MASK]', 'during', 'this', 'pointless', '[MASK]', ')', '.', '[MASK]', 'br']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_dataset[\"train\"][i] for i in range(3)]\n",
    "for sample in samples:\n",
    "    _ = sample.pop(\"word_ids\")\n",
    "    _ = sample.pop(\"offset_mapping\")\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(tokenizer.convert_ids_to_tokens(chunk))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9247fd76",
   "metadata": {},
   "source": [
    "Nice, it worked! We can see that the `[MASK]` token has been randomly inserted at various locations in our text. These will be the tokens which our model will have to predict during training — and the beauty of the data collator is that it will randomize the `[MASK]` insertion with every batch!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c90ad9a",
   "metadata": {},
   "source": [
    "One side effect of random masking is that our evaluation metrics will not be deterministic when using the `Trainer`, since we use the same data collator for the training and test sets. We’ll see later, when we look at fine-tuning with 🤗 Accelerate, how we can use the flexibility of a custom evaluation loop to freeze the randomness.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c2f67d",
   "metadata": {},
   "source": [
    "When training models for masked language modeling, one technique that can be used is to mask whole words together, not just individual tokens. This approach is called whole word masking. If we want to use whole word masking, we will need to build a data collator ourselves. A data collator is just a function that takes a list of samples and converts them into a batch, so let’s do this now! We’ll use the word IDs computed earlier to make a map between word indices and the corresponding tokens, then randomly decide which words to mask and apply that mask on the inputs. Note that the labels are all `-100` except for the ones corresponding to mask words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571ebd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "from transformers import default_data_collator\n",
    "wwm_probability = 0.2\n",
    "\n",
    "def whole_word_masking_data_collator(features):\n",
    "    for feature in features:\n",
    "        _ = feature.pop(\"offset_mapping\", None)\n",
    "        word_ids = feature.pop(\"word_ids\")\n",
    "        # Create a map between words and corresponding token indices\n",
    "        mapping = collections.defaultdict(list)\n",
    "        current_word_idx = -1\n",
    "        current_idx = None\n",
    "        for idx, word_idx in enumerate(word_ids):\n",
    "            if word_idx != None:\n",
    "                if word_idx != current_idx:\n",
    "                    current_idx = word_idx\n",
    "                    current_word_idx += 1\n",
    "                mapping[current_word_idx].append(idx)\n",
    "\n",
    "        # Randomly mask words\n",
    "        mask = np.random.binomial(1, wwm_probability, (len(mapping), ))\n",
    "        input_ids = feature[\"input_ids\"]\n",
    "        labels = feature[\"labels\"]\n",
    "        new_labels = [-100] * len(labels)\n",
    "\n",
    "        for word_id in np.where(mask)[0]:\n",
    "            word_id = word_id.item()\n",
    "            for idx in mapping[word_id]:\n",
    "                input_ids[idx] = tokenizer.mask_token_id\n",
    "                new_labels[idx] = labels[idx]\n",
    "        feature[\"labels\"] = new_labels\n",
    "\n",
    "    return default_data_collator(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21df833",
   "metadata": {},
   "source": [
    "Next, we can try it on the same samples as before:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44751ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] i [MASK] [MASK] am curious - yellow from [MASK] video store because of all the controversy that [MASK] [MASK] when it was first [MASK] in [MASK]. i also heard that at first it [MASK] seized by u. s. customs [MASK] it [MASK] tried to enter this country, [MASK] being a fan [MASK] [MASK] considered \" [MASK] \" [MASK] really had to see this for myself [MASK] < br / [MASK] [MASK] br [MASK] > the plot [MASK] centered around a young [MASK] drama student named lena who [MASK] [MASK] learn everything she can about life. in [MASK] she wants to focus her attentions to [MASK] [MASK] sort of documentary on [MASK] the average swede thought about certain political issues such [MASK] the [MASK] war and [MASK] [MASK] in [MASK] [MASK] states. in between asking politicians [MASK] ordinary [MASK] [MASK] [MASK] of stockholm [MASK] [MASK] opinions on politics, she has [MASK] with her drama teacher [MASK] classmates, and married men. < br / > < br / [MASK] what [MASK] [MASK] about i am curious - yellow is that 40 years ago, this was [MASK] pornographic. [MASK], the sex and nudity scenes are few and far between, [MASK] [MASK] it ' s not shot like some cheaply made [MASK] [MASK]. while my countrymen mind find [MASK] [MASK], in reality sex and nudity are a major staple in swedish cinema. even [MASK] [MASK] bergman,\n",
      "['[CLS]', 'i', '[MASK]', '[MASK]', 'am', 'curious', '-', 'yellow', 'from', '[MASK]', 'video', 'store', 'because', 'of', 'all', 'the', 'controversy', 'that', '[MASK]', '[MASK]', 'when', 'it', 'was', 'first', '[MASK]', 'in', '[MASK]', '.', 'i', 'also', 'heard', 'that', 'at', 'first', 'it', '[MASK]', 'seized', 'by', 'u', '.', 's', '.', 'customs', '[MASK]', 'it', '[MASK]', 'tried', 'to', 'enter', 'this', 'country', ',', '[MASK]', 'being', 'a', 'fan', '[MASK]', '[MASK]', 'considered', '\"', '[MASK]', '\"', '[MASK]', 'really', 'had', 'to', 'see', 'this', 'for', 'myself', '[MASK]', '<', 'br', '/', '[MASK]', '[MASK]', 'br', '[MASK]', '>', 'the', 'plot', '[MASK]', 'centered', 'around', 'a', 'young', '[MASK]', 'drama', 'student', 'named', 'lena', 'who', '[MASK]', '[MASK]', 'learn', 'everything', 'she', 'can', 'about', 'life', '.', 'in', '[MASK]', 'she', 'wants', 'to', 'focus', 'her', 'attention', '##s', 'to', '[MASK]', '[MASK]', 'sort', 'of', 'documentary', 'on', '[MASK]', 'the', 'average', 'sw', '##ede', 'thought', 'about', 'certain', 'political', 'issues', 'such', '[MASK]', 'the', '[MASK]', 'war', 'and', '[MASK]', '[MASK]', 'in', '[MASK]', '[MASK]', 'states', '.', 'in', 'between', 'asking', 'politicians', '[MASK]', 'ordinary', '[MASK]', '[MASK]', '[MASK]', 'of', 'stockholm', '[MASK]', '[MASK]', 'opinions', 'on', 'politics', ',', 'she', 'has', '[MASK]', 'with', 'her', 'drama', 'teacher', '[MASK]', 'classmates', ',', 'and', 'married', 'men', '.', '<', 'br', '/', '>', '<', 'br', '/', '[MASK]', 'what', '[MASK]', '[MASK]', 'about', 'i', 'am', 'curious', '-', 'yellow', 'is', 'that', '40', 'years', 'ago', ',', 'this', 'was', '[MASK]', 'pornographic', '.', '[MASK]', ',', 'the', 'sex', 'and', 'nu', '##dity', 'scenes', 'are', 'few', 'and', 'far', 'between', ',', '[MASK]', '[MASK]', 'it', \"'\", 's', 'not', 'shot', 'like', 'some', 'cheap', '##ly', 'made', '[MASK]', '[MASK]', '.', 'while', 'my', 'country', '##men', 'mind', 'find', '[MASK]', '[MASK]', ',', 'in', 'reality', 'sex', 'and', 'nu', '##dity', 'are', 'a', 'major', 'staple', 'in', 'swedish', 'cinema', '.', 'even', '[MASK]', '[MASK]', 'bergman', ',']\n",
      "\n",
      "arguably their answer to good old [MASK] john ford, had sex [MASK] in his films. < br / > < [MASK] [MASK] > i [MASK] commend the filmmakers [MASK] the [MASK] that any sex shown in the film [MASK] shown for artistic purposes rather than just to shock people [MASK] make money to be shown [MASK] pornographic [MASK] in america. i am curious - yellow [MASK] [MASK] good film for anyone wanting to study the meat and potatoes ( no [MASK] intended ) of [MASK] cinema. but [MASK], this film doesn ' t have much [MASK] a plot. [SEP] [CLS] \" i am curious : yellow \" [MASK] [MASK] risible and pretentious steaming [MASK] [MASK] it doesn ' t matter what [MASK] [MASK] s political views are because [MASK] film [MASK] hardly be taken seriously [MASK] [MASK] level. as [MASK] the [MASK] that frontal male [MASK] [MASK] is an [MASK] nc - [MASK], [MASK] [MASK] ' t true. [MASK] ' [MASK] seen [MASK] - rated [MASK] with male nudity. granted, they only offer [MASK] fleeting views, [MASK] where [MASK] the r - rated films [MASK] gaping vulvas [MASK] flapping labia [MASK] [MASK], because they [MASK] [MASK] [MASK] exist. the same goes for those [MASK] [MASK] cable shows [MASK] schlongs swinging [MASK] the breeze but not a [MASK] [MASK] in sight [MASK] and [MASK] pretentious indie movies like\n",
      "['arguably', 'their', 'answer', 'to', 'good', 'old', '[MASK]', 'john', 'ford', ',', 'had', 'sex', '[MASK]', 'in', 'his', 'films', '.', '<', 'br', '/', '>', '<', '[MASK]', '[MASK]', '>', 'i', '[MASK]', 'com', '##men', '##d', 'the', 'filmmakers', '[MASK]', 'the', '[MASK]', 'that', 'any', 'sex', 'shown', 'in', 'the', 'film', '[MASK]', 'shown', 'for', 'artistic', 'purposes', 'rather', 'than', 'just', 'to', 'shock', 'people', '[MASK]', 'make', 'money', 'to', 'be', 'shown', '[MASK]', 'pornographic', '[MASK]', 'in', 'america', '.', 'i', 'am', 'curious', '-', 'yellow', '[MASK]', '[MASK]', 'good', 'film', 'for', 'anyone', 'wanting', 'to', 'study', 'the', 'meat', 'and', 'potatoes', '(', 'no', '[MASK]', 'intended', ')', 'of', '[MASK]', 'cinema', '.', 'but', '[MASK]', ',', 'this', 'film', 'doesn', \"'\", 't', 'have', 'much', '[MASK]', 'a', 'plot', '.', '[SEP]', '[CLS]', '\"', 'i', 'am', 'curious', ':', 'yellow', '\"', '[MASK]', '[MASK]', 'ri', '##sible', 'and', 'pre', '##ten', '##tious', 'steaming', '[MASK]', '[MASK]', 'it', 'doesn', \"'\", 't', 'matter', 'what', '[MASK]', '[MASK]', 's', 'political', 'views', 'are', 'because', '[MASK]', 'film', '[MASK]', 'hardly', 'be', 'taken', 'seriously', '[MASK]', '[MASK]', 'level', '.', 'as', '[MASK]', 'the', '[MASK]', 'that', 'frontal', 'male', '[MASK]', '[MASK]', 'is', 'an', '[MASK]', 'nc', '-', '[MASK]', ',', '[MASK]', '[MASK]', \"'\", 't', 'true', '.', '[MASK]', \"'\", '[MASK]', 'seen', '[MASK]', '-', 'rated', '[MASK]', 'with', 'male', 'nu', '##dity', '.', 'granted', ',', 'they', 'only', 'offer', '[MASK]', 'fleeting', 'views', ',', '[MASK]', 'where', '[MASK]', 'the', 'r', '-', 'rated', 'films', '[MASK]', 'gaping', 'vu', '##lva', '##s', '[MASK]', 'flap', '##ping', 'lab', '##ia', '[MASK]', '[MASK]', ',', 'because', 'they', '[MASK]', '[MASK]', '[MASK]', 'exist', '.', 'the', 'same', 'goes', 'for', 'those', '[MASK]', '[MASK]', 'cable', 'shows', '[MASK]', 'sc', '##hl', '##ong', '##s', 'swinging', '[MASK]', 'the', 'breeze', 'but', 'not', 'a', '[MASK]', '[MASK]', 'in', 'sight', '[MASK]', 'and', '[MASK]', 'pre', '##ten', '##tious', 'indie', 'movies', 'like']\n",
      "\n",
      "[MASK] brown bunny, in [MASK] we [MASK] re treated to the site of [MASK] gallo ' s throbbing johnson [MASK] but not [MASK] trace of pink visible on chloe [MASK] [MASK] [MASK]. before crying ( [MASK] implying ) \" [MASK] - standard \" in matters [MASK] nudity, the mentally obtuse should [MASK] into account one unavoidably obvious anatomical difference between [MASK] and women : there [MASK] no [MASK] [MASK] [MASK] on display when actresses appears nude, and the same cannot be said for [MASK] man [MASK] in fact, [MASK] [MASK] [MASK] [MASK] t see female genitals in an american film in [MASK] short of [MASK] or explicit erotica. this alleged double - standard is [MASK] a [MASK] standard than an admittedly [MASK] [MASK] [MASK] to come to terms culturally with the insides of women ' s bodies [MASK] [SEP] [CLS] if only [MASK] [MASK] making this type of [MASK] in [MASK] future. this [MASK] is interesting [MASK] [MASK] [MASK] but tells no cogent [MASK]. < br / > < [MASK] [MASK] > one might feel virtuous for sitting thru [MASK] [MASK] it touches on [MASK] many important issues but it does so [MASK] any discernable [MASK] [MASK] [MASK] [MASK] comes [MASK] [MASK] no new perspectives ( unless one comes [MASK] with [MASK] while one ' s mind [MASK] [MASK] [MASK] as it will invariably do during this pointless film ). [MASK] br\n",
      "['[MASK]', 'brown', 'bunny', ',', 'in', '[MASK]', 'we', '[MASK]', 're', 'treated', 'to', 'the', 'site', 'of', '[MASK]', 'gallo', \"'\", 's', 'throbbing', 'johnson', '[MASK]', 'but', 'not', '[MASK]', 'trace', 'of', 'pink', 'visible', 'on', 'chloe', '[MASK]', '[MASK]', '[MASK]', '.', 'before', 'crying', '(', '[MASK]', 'implying', ')', '\"', '[MASK]', '-', 'standard', '\"', 'in', 'matters', '[MASK]', 'nu', '##dity', ',', 'the', 'mentally', 'ob', '##tus', '##e', 'should', '[MASK]', 'into', 'account', 'one', 'una', '##vo', '##ida', '##bly', 'obvious', 'anatomical', 'difference', 'between', '[MASK]', 'and', 'women', ':', 'there', '[MASK]', 'no', '[MASK]', '[MASK]', '[MASK]', 'on', 'display', 'when', 'actresses', 'appears', 'nude', ',', 'and', 'the', 'same', 'cannot', 'be', 'said', 'for', '[MASK]', 'man', '[MASK]', 'in', 'fact', ',', '[MASK]', '[MASK]', '[MASK]', '[MASK]', 't', 'see', 'female', 'gen', '##ital', '##s', 'in', 'an', 'american', 'film', 'in', '[MASK]', 'short', 'of', '[MASK]', 'or', 'explicit', 'erotic', '##a', '.', 'this', 'alleged', 'double', '-', 'standard', 'is', '[MASK]', 'a', '[MASK]', 'standard', 'than', 'an', 'admitted', '##ly', '[MASK]', '[MASK]', '[MASK]', 'to', 'come', 'to', 'terms', 'culturally', 'with', 'the', 'insides', 'of', 'women', \"'\", 's', 'bodies', '[MASK]', '[SEP]', '[CLS]', 'if', 'only', '[MASK]', '[MASK]', 'making', 'this', 'type', 'of', '[MASK]', 'in', '[MASK]', 'future', '.', 'this', '[MASK]', 'is', 'interesting', '[MASK]', '[MASK]', '[MASK]', 'but', 'tells', 'no', 'co', '##gent', '[MASK]', '.', '<', 'br', '/', '>', '<', '[MASK]', '[MASK]', '>', 'one', 'might', 'feel', 'vi', '##rt', '##uous', 'for', 'sitting', 'thru', '[MASK]', '[MASK]', 'it', 'touches', 'on', '[MASK]', 'many', 'important', 'issues', 'but', 'it', 'does', 'so', '[MASK]', 'any', 'disc', '##ern', '##able', '[MASK]', '[MASK]', '[MASK]', '[MASK]', 'comes', '[MASK]', '[MASK]', 'no', 'new', 'perspectives', '(', 'unless', 'one', 'comes', '[MASK]', 'with', '[MASK]', 'while', 'one', \"'\", 's', 'mind', '[MASK]', '[MASK]', '[MASK]', 'as', 'it', 'will', 'invariably', 'do', 'during', 'this', 'pointless', 'film', ')', '.', '[MASK]', 'br']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_dataset[\"train\"][i] for i in range(3)]\n",
    "batch = whole_word_masking_data_collator(samples)\n",
    "for chunk in batch[\"input_ids\"]:\n",
    "    print(tokenizer.decode(chunk))\n",
    "    print(tokenizer.convert_ids_to_tokens(chunk))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e100272",
   "metadata": {},
   "source": [
    "Now that we have two data collators, the rest of the fine-tuning steps are standard. Training can take a while on Google Colab if you’re not lucky enough to score a mythical P100 GPU 😭, so we’ll first downsample the size of the training set to a few thousand examples. Don’t worry, we’ll still get a pretty decent language model! A quick way to downsample a dataset in 🤗 Datasets is via the `Dataset.train_test_split()` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29e63fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'word_ids', 'labels'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'word_ids', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = 10_000\n",
    "test_size = int(0.1 * train_size)\n",
    "\n",
    "downsampled_dataset = lm_dataset[\"train\"].train_test_split(\n",
    "    train_size=train_size,\n",
    "    test_size=test_size,\n",
    "    seed=42\n",
    ")\n",
    "downsampled_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25c9223",
   "metadata": {},
   "source": [
    "This has automatically created new `train` and `test` splits, with the training set size set to 10,000 examples and the validation set to 10% of that — feel free to increase this if you have a beefy GPU! The next thing we need to do is log in to the Hugging Face Hub. If you’re running this code in a notebook, you can do so with the following utility function:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6f8a75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e342f7f21b42b6a19b4a549e0f6ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4727b48b",
   "metadata": {},
   "source": [
    "Once we’re logged in, we can specify the arguments for the `Trainer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d053092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 64\n",
    "# Show the training loss every epoch\n",
    "logging_steps = len(downsampled_dataset[\"train\"]) // batch_size\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{checkpoint}-finetuned-imdb-mlm\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    per_device_eval_batch_size=4,\n",
    "    per_device_train_batch_size=4,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=True,\n",
    "    fp16=True,\n",
    "    remove_unused_columns=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7e63ac",
   "metadata": {},
   "source": [
    "By default, the `Trainer` will remove any columns that are not part of the model’s `forward()` method. This means that if you’re using the whole word masking collator, you’ll also need to set `remove_unused_columns=False` to ensure we don’t lose the `word_ids` column during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04bbdff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=downsampled_dataset[\"train\"],\n",
    "    eval_dataset=downsampled_dataset[\"test\"],\n",
    "    data_collator=whole_word_masking_data_collator,\n",
    "    processing_class=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e4c97c",
   "metadata": {},
   "source": [
    "We’re now ready to run `trainer.train()` — but before doing so let’s briefly look at **perplexity**, which is a common metric to evaluate the performance of language models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9534e2c4",
   "metadata": {},
   "source": [
    "### Perplexity for language models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af08776",
   "metadata": {},
   "source": [
    "Unlike other tasks like text classification or question answering where we’re given a labeled corpus to train on, with language modeling we don’t have any explicit labels. So how do we determine what makes a good language model? Like with the autocorrect feature in your phone, a good language model is one that assigns high probabilities to sentences that are grammatically correct, and low probabilities to nonsense sentences. To give you a better idea of what this looks like, you can find whole sets of “autocorrect fails” online, where the model in a person’s phone has produced some rather funny (and often inappropriate) completions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be881c87",
   "metadata": {},
   "source": [
    "Assuming our test set consists mostly of sentences that are grammatically correct, then one way to measure the quality of our language model is to calculate the probabilities it assigns to the next word in all the sentences of the test set. High probabilities indicates that the model is not “surprised” or “perplexed” by the unseen examples, and suggests it has learned the basic patterns of grammar in the language. There are various mathematical definitions of perplexity, but the one we’ll use defines it as the exponential of the cross-entropy loss. Thus, we can calculate the perplexity of our pretrained model by using the `Trainer.evaluate()` function to compute the cross-entropy loss on the test set and then taking the exponential of the result:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c5bccd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 03:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 55.42\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cfd344",
   "metadata": {},
   "source": [
    "A lower perplexity score means a better language model, and we can see here that our starting model has a somewhat large value. Let’s see if we can lower it by fine-tuning! To do that, we first run the training loop:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b6f6d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7500' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7500/7500 14:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.278276</td>\n",
       "      <td>3.144236</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.168640</td>\n",
       "      <td>3.106678</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.108943</td>\n",
       "      <td>3.090636</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8ddb678fe94ab4b019ba4d9a277d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967c8057cde5480fbed4e26504541f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c54f5b19b343309737f11af0e742c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bccfc500a19471aafcbd0b24d6dbe23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff8e1cb5b1242588e90827dfea7685d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e476a918044af9bb5b538066ffeb45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100da664bc0646c78c500a7b08a68fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe24845ba5d436e966fc771cf837ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ba3c51cdf846b4aa610b6424ac54d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8810eb251b554bb2bdac54e37595241c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202c073bda2142a19553b88f369f5bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995725bcc79b4909b636a481fe3dfaee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf09b4608ed4556833e6924d8b1abf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0061920a23e4f0da2c73b817f67298c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b71db1fa4241528b2ed7cc12b4fcc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7500, training_loss=3.2211912419637043, metrics={'train_runtime': 887.5073, 'train_samples_per_second': 33.803, 'train_steps_per_second': 8.451, 'total_flos': 1988417341440000.0, 'train_loss': 3.2211912419637043, 'epoch': 3.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96323519",
   "metadata": {},
   "source": [
    "and then compute the resulting perplexity on the test set as before:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1cd4867b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 21.84\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b75c3fb",
   "metadata": {},
   "source": [
    "Nice — this is quite a reduction in perplexity, which tells us the model has learned something about the domain of movie reviews!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4824fc",
   "metadata": {},
   "source": [
    "Once training is finished, we can push the model card with the training information to the Hub (the checkpoints are saved during training itself):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdb34aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4918533533f4efa80dc0e9e2fbda479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e64499b2a6472495f867acfd0d9767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75962b58460c4c29a4c1b9a311fad176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a00f5965fba4b619a8638ddfd2f4173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...mdb-mlm/training_args.bin: 100%|##########| 5.20kB / 5.20kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febe9fac5adf4ae09b3939aa7a5bb088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...mdb-mlm/model.safetensors:  12%|#2        | 33.4MB /  268MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/arraypowerplay/distilbert-base-uncased-finetuned-imdb-mlm/commit/bbcb4c8668c5c26b22a64ecb4538c4872506bcb7', commit_message='End of training', commit_description='', oid='bbcb4c8668c5c26b22a64ecb4538c4872506bcb7', pr_url=None, repo_url=RepoUrl('https://huggingface.co/arraypowerplay/distilbert-base-uncased-finetuned-imdb-mlm', endpoint='https://huggingface.co', repo_type='model', repo_id='arraypowerplay/distilbert-base-uncased-finetuned-imdb-mlm'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f1463a",
   "metadata": {},
   "source": [
    "## 5. Fine-tuning DistilBERT with 🤗 Accelerate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6e475e",
   "metadata": {},
   "source": [
    "As we saw with the `Trainer`, fine-tuning a masked language model is very similar to the text classification. In fact, the only subtlety is the use of a special data collator, and we’ve already covered that earlier in this section!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671ec5cd",
   "metadata": {},
   "source": [
    "However, we want to use whole word masking to mask entire words at once. To do this, we'll use `DataCollatorForWholeWordMask` which properly handles the `word_ids` structure. We can apply the masking once on the whole test set to eliminate randomness in evaluation, then use the default data collator for the evaluation set. To see how this works, let's implement a simple function that applies the masking on a batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "989527c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/data/data_collator.py:1028: FutureWarning: DataCollatorForWholeWordMask is deprecated and will be removed in a future version, you can now use DataCollatorForLanguageModeling with whole_word_mask=True instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForWholeWordMask, default_data_collator\n",
    "\n",
    "wwm_data_collator = DataCollatorForWholeWordMask(tokenizer=tokenizer)\n",
    "\n",
    "def to_wwm_features(batch):\n",
    "    # DataColator only accepts input as list of individual examples\n",
    "    # We have to convert batch to individual examples\n",
    "    return [\n",
    "        {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"offset_mapping\": [tuple(pair) for pair in offset_mapping],\n",
    "        }\n",
    "        for input_ids, attention_mask, offset_mapping in zip(\n",
    "            batch[\"input_ids\"],\n",
    "            batch[\"attention_mask\"],\n",
    "            batch[\"offset_mapping\"],\n",
    "        )\n",
    "    ]\n",
    "\n",
    "def collate_wwm_from_batch(batch):\n",
    "    return wwm_data_collator(to_wwm_features(batch))\n",
    "\n",
    "\n",
    "def insert_random_mask(batch):\n",
    "    # Labels are created inside DataCollator\n",
    "    masked_inputs = collate_wwm_from_batch(batch)\n",
    "    return {\n",
    "        \"masked_input_ids\": masked_inputs[\"input_ids\"].numpy(),\n",
    "        \"masked_attention_mask\": masked_inputs[\"attention_mask\"].numpy(),\n",
    "        \"masked_labels\": masked_inputs[\"labels\"].numpy(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addddb0c",
   "metadata": {},
   "source": [
    "Now let's apply this whole word masking function to create the masked evaluation dataset. We'll apply the masking to the test set and convert the masked columns to a format suitable for evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e719cbfe",
   "metadata": {},
   "source": [
    "Next, we'll apply this function to our test set and drop the unmasked columns so we can replace them with the masked ones. The `DataCollatorForWholeWordMask` will properly handle the `word_ids` structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "331b17c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa17b15f7034f0db1b50e1f9efafa8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_dataset = downsampled_dataset[\"test\"].map(\n",
    "    insert_random_mask,\n",
    "    batched=True,\n",
    "    remove_columns=downsampled_dataset[\"test\"].column_names\n",
    ")\n",
    "\n",
    "eval_dataset = eval_dataset.rename_columns(\n",
    "    {\n",
    "        \"masked_input_ids\": \"input_ids\",\n",
    "        \"masked_attention_mask\": \"attention_mask\",\n",
    "        \"masked_labels\": \"labels\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c0a71",
   "metadata": {},
   "source": [
    "We can then set up the dataloaders as usual, but we’ll use the `default_data_collator` from 🤗 Transformers for the evaluation set:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7477e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "\n",
    "def train_collate_fn(features):\n",
    "    # WholeWordDataCollator doesn't expect the 'word_ids' so we have to create\n",
    "    # a new way to input data into WholeWordDataCollator\n",
    "    batch = {\n",
    "        \"input_ids\": [feature[\"input_ids\"] for feature in features],\n",
    "        \"attention_mask\": [feature[\"attention_mask\"] for feature in features],\n",
    "        \"offset_mapping\": [feature[\"offset_mapping\"] for feature in features],\n",
    "    }\n",
    "    return collate_wwm_from_batch(batch)\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    downsampled_dataset[\"train\"],\n",
    "    # batch_size here is local_batch_size after putting into accelerator\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=train_collate_fn,\n",
    "    # collate_fn=wwm_data_collator,\n",
    " )\n",
    "\n",
    "eval_dataloader = torch.utils.data.DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72808ed8",
   "metadata": {},
   "source": [
    "Form here, we follow the standard steps with 🤗 Accelerate. The first order of business is to load a fresh version of the pretrained model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68759e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5017fcaeea84484987ff5edc210f872e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eed3e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e39d95",
   "metadata": {},
   "source": [
    "With these objects, we can now prepare everything for training with the `Accelerator` object:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef6b384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c34628c3d524677984f98d69e9f1fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "221b4522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 3\n",
    "num_training_steps = num_train_epochs * len(train_dataloader)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0883dc04",
   "metadata": {},
   "source": [
    "There is just one last thing to do before training: create a model repository on the Hugging Face Hub! We can use the 🤗 Hub library to first generate the full name of our repo:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e298b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (1.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.24.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.3)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.3)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (0.24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (4.12.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub) (0.16.0)\n",
      "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub) (0.24.0)\n",
      "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface_hub) (8.3.1)\n",
      "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface_hub) (13.9.4)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface_hub) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8b27de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'arraypowerplay/distilbert-base-uncased-finetuned-imdb-accelerate'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import get_full_repo_name, create_repo, HfApi\n",
    "\n",
    "model_name = \"distilbert-base-uncased-finetuned-imdb-accelerate\"\n",
    "repo_name = get_full_repo_name(model_name)\n",
    "create_repo(repo_name, exist_ok=True)\n",
    "output_dir = model_name\n",
    "\n",
    "api = HfApi()\n",
    "repo_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2f1523",
   "metadata": {},
   "source": [
    "With that done, it’s just a simple matter of writing out the full training and evaluation loop:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "203c6679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cb294f087a42ddaff3f1ed193b518c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/471 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Perlexity: 20.13598276435076\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e6e049500549a8998544816129e225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2ce39938bb41dba2cc6c80cbec310e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a283099e1b6a491688107ac94434e2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcfda1829404268a38e08e7f5908827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...elerate/model.safetensors:   0%|          |  575kB /  268MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "Perlexity: 18.976032706171683\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb8104def5a4431ae722d77dd02bc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6c382942e649eda1ce140b948bbf22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c2da59eb83457a8683c984ffd93917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0476f476c7ca46bb98fa76eccfd0827b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...elerate/model.safetensors:   0%|          |  575kB /  268MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "Perlexity: 18.676848665146906\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835a92b0eb544966b3866d5bf154b71d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe695ac0ccf4a4e80a952d481fe08b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c48d6e57194429a9ecd15daf058c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10aca2cb825a45b0b5911eab52f73ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...elerate/model.safetensors:   0%|          |  575kB /  268MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "        accelerator.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for batch in eval_dataloader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            # current_batch_size here is the local batch_size of each GPU\n",
    "            current_batch_size = batch[\"input_ids\"].shape[0]\n",
    "            losses.append(accelerator.gather(loss.repeat(current_batch_size)))\n",
    "    losses = torch.cat(losses)\n",
    "    losses = losses[:len(eval_dataset)]\n",
    "    try:\n",
    "        perplexity = math.exp(torch.mean(losses))\n",
    "    except OverflowError:\n",
    "        perplexity = float(\"inf\")\n",
    "    print(f\"Epoch: {epoch + 1}\\nPerlexity: {perplexity}\")\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    \n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        api.upload_folder(\n",
    "            folder_path=output_dir,\n",
    "            repo_id=repo_name,\n",
    "            commit_message=f\"Training progress in epoch {epoch + 1}.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf4cd8e",
   "metadata": {},
   "source": [
    "Cool, we’ve been able to evaluate perplexity with each epoch and ensure that multiple training runs are reproducible!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce317ed8",
   "metadata": {},
   "source": [
    "## 6. Using our fine-tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0ab9c3",
   "metadata": {},
   "source": [
    "You can interact with your fine-tuned model either by using its widget on the Hub or locally with the `pipeline` from 🤗 Transformers. Let’s use the latter to download our model using the `fill-mask` pipeline:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "053ae140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ead76c7bcf4a45ace30b44673be5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad703963a2841409df305cbc1592a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64d5fdd419c4946bf70c42948d48ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5514986dd0443899f67e00e40e8914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/322 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f90721d0e4b4e9797965ec936a3c57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "mask_filler = pipeline(\n",
    "    \"fill-mask\", model='arraypowerplay/distilbert-base-uncased-finetuned-imdb-accelerate'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cb407d",
   "metadata": {},
   "source": [
    "We can then feed the pipeline our sample text of “This is a great [MASK]” and see what the top 5 predictions are:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "15a807ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.05452856421470642\n",
      "token: 2801\n",
      "token_str: idea\n",
      "sequence: this is a great idea.\n",
      "\n",
      "score: 0.046769678592681885\n",
      "token: 2143\n",
      "token_str: film\n",
      "sequence: this is a great film.\n",
      "\n",
      "score: 0.03162470832467079\n",
      "token: 3185\n",
      "token_str: movie\n",
      "sequence: this is a great movie.\n",
      "\n",
      "score: 0.02737979032099247\n",
      "token: 6172\n",
      "token_str: adventure\n",
      "sequence: this is a great adventure.\n",
      "\n",
      "score: 0.023253317922353745\n",
      "token: 3066\n",
      "token_str: deal\n",
      "sequence: this is a great deal.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# By default, preds returns a list of 5 highest possible tokens \n",
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    # pred returns:\n",
    "    # score: probability of predicted token\n",
    "    # token: ID of token\n",
    "    # token_str: token\n",
    "    # sequence: whole sequence after filling mask\n",
    "    for key, value in pred.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
